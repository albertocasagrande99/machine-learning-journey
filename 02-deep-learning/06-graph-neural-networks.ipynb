{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e29dc710",
   "metadata": {
    "id": "e29dc710"
   },
   "source": [
    "# An Introduction to Graph Neural Networks (GNNs) üåê\n",
    "\n",
    "**Contents**\n",
    "1. Why graphs? When to use GNNs\n",
    "2. Message passing intuition and the GCN formula\n",
    "3. Installing / importing PyTorch Geometric (optional)\n",
    "4. Loading the Cora dataset (Planetoid)\n",
    "5. Inspecting graph data in PyG (`Data` object)\n",
    "6. Building a simple 2-layer GCN (implementation + explanation)\n",
    "7. Training loop (full-batch) and evaluation using train/val/test masks\n",
    "8. Inspecting predictions on specific nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353bcc0",
   "metadata": {
    "id": "4353bcc0"
   },
   "source": [
    "## Why graphs? ‚Äî Motivation\n",
    "\n",
    "Many real-world data are naturally represented as graphs: social networks, molecules, knowledge graphs, citation networks, recommender systems, and more. Traditional ML models (MLPs, CNNs, RNNs) assume fixed-size vectors, grids, or sequences; they don't directly model relationships between entities. GNNs operate **directly on graph-structured data** and propagate information along edges, letting each node aggregate information from its neighbours.\n",
    "\n",
    "**Use cases**\n",
    "- Node classification (e.g., predict paper topic in a citation graph) ‚Äî *this notebook's task*\n",
    "- Graph classification (e.g., molecule property prediction)\n",
    "- Link prediction (e.g., recommend new friendships)\n",
    "- Graph-level regression (e.g., molecular energy)\n",
    "\n",
    "We will focus on **node classification** on the Cora citation graph: nodes = papers, edges = citations, features = bag-of-words of paper abstracts, labels = topic class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae583a4",
   "metadata": {
    "id": "aae583a4"
   },
   "source": [
    "## The Core Idea of GNNs: Message Passing\n",
    "\n",
    "The fundamental mechanism behind GNNs is **message passing** (or neighborhood aggregation). A GNN layer updates each node's representation by performing two key steps:\n",
    "\n",
    "1.  **Aggregate:** Each node collects feature vectors (or \"messages\") from its immediate neighbors. Common aggregation functions include taking the sum, mean, or max of the neighbor features.\n",
    "\n",
    "2.  **Update:** Each node updates its own feature vector by combining its current vector with the aggregated message from its neighbors. This combination is typically done using a small neural network (e.g., a linear layer followed by an activation function).\n",
    "\n",
    "By stacking multiple GNN layers, a node can gather information from nodes that are further and further away. A 2-layer GNN allows a node to receive information from its 2-hop neighborhood (its friends, and its friends' friends)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78a6ea",
   "metadata": {
    "id": "1e78a6ea"
   },
   "source": [
    "## Setup: PyTorch Geometric (PyG)\n",
    "\n",
    "We will use PyTorch Geometric (PyG), which provides efficient message passing primitives and dataset loaders. Installing PyG requires matching wheels for your PyTorch and CUDA versions. The cell below shows how to install PyG ‚Äî **run it only if PyG is not installed**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27842d77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10682,
     "status": "ok",
     "timestamp": 1760123671478,
     "user": {
      "displayName": "Alberto Casagrande",
      "userId": "03712360769530450037"
     },
     "user_tz": -120
    },
    "id": "27842d77",
    "outputId": "a15b0430-70ed-4dfc-abb2-70b1ce5ca061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_scatter-2.1.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_sparse-0.6.18%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_cluster-1.6.3%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch-spline-conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_spline_conv-1.2.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
      "Successfully installed torch-cluster-1.6.3+pt28cu126 torch-geometric-2.6.1 torch-scatter-2.1.2+pt28cu126 torch-sparse-0.6.18+pt28cu126 torch-spline-conv-1.2.2+pt28cu126\n",
      "If PyG is not installed, follow the instructions at https://pytorch-geometric.readthedocs.io/\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: install PyG (uncomment to run if PyG is not installed)\n",
    "# This installation command depends on your PyTorch version and system.\n",
    "# Uncomment and run only if you need to install PyG in this environment.\n",
    "#\n",
    "# import torch\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "#\n",
    "print('If PyG is not installed, follow the instructions at https://pytorch-geometric.readthedocs.io/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0641224",
   "metadata": {
    "id": "c0641224"
   },
   "source": [
    "## Loading the Cora dataset (Planetoid)\n",
    "\n",
    "We'll use the `Planetoid` loader from PyG which provides Cora, CiteSeer, and PubMed.\n",
    "\n",
    "The dataset contains:\n",
    "- `data.x`: node feature matrix (num_nodes √ó num_node_features)\n",
    "- `data.edge_index`: COO-format edge list (2 √ó num_edges)\n",
    "- `data.y`: labels for nodes\n",
    "- `data.train_mask`, `data.val_mask`, `data.test_mask`: boolean masks for splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79ca709",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16196,
     "status": "ok",
     "timestamp": 1760123687742,
     "user": {
      "displayName": "Alberto Casagrande",
      "userId": "03712360769530450037"
     },
     "user_tz": -120
    },
    "id": "e79ca709",
    "outputId": "0178f163-3b29-4ac9-86c2-1bc8a950ca01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: Cora\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Imports and dataset loading\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "# Download/load Cora (Planetoid)\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "print('Loaded dataset:', dataset.name)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cbb12",
   "metadata": {
    "id": "c19cbb12"
   },
   "source": [
    "## Inspecting the graph data\n",
    "\n",
    "Let's print basic statistics and understand the `Data` object fields. We also explain `edge_index`'s COO format and how PyG expects full-batch training for small citation graphs like Cora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02407f3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1760123895112,
     "user": {
      "displayName": "Alberto Casagrande",
      "userId": "03712360769530450037"
     },
     "user_tz": -120
    },
    "id": "02407f3d",
    "outputId": "abacfbe1-76ba-4ec6-f9ca-37542ff1ced0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Num node features: 1433\n",
      "Num classes: 7\n",
      "Data object keys: <bound method BaseData.keys of Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])>\n",
      "x shape: torch.Size([2708, 1433])\n",
      "edge_index shape: torch.Size([2, 10556])\n",
      "y shape: torch.Size([2708])\n",
      "train/val/test counts: 140 500 1000\n"
     ]
    }
   ],
   "source": [
    "print('Number of nodes:', data.num_nodes)\n",
    "print('Number of edges:', data.num_edges)\n",
    "print('Num node features:', dataset.num_node_features)\n",
    "print('Num classes:', dataset.num_classes)\n",
    "print('Data object keys:', data.keys)\n",
    "\n",
    "# Show example shapes\n",
    "print('x shape:', data.x.shape)\n",
    "print('edge_index shape:', data.edge_index.shape)\n",
    "print('y shape:', data.y.shape)\n",
    "print('train/val/test counts:', int(data.train_mask.sum()), int(data.val_mask.sum()), int(data.test_mask.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74bf18c",
   "metadata": {
    "id": "a74bf18c"
   },
   "source": [
    "## Building a simple 2-layer GCN\n",
    "\n",
    "We implement a compact model with two `GCNConv` layers:\n",
    "- `conv1`: input features ‚Üí hidden_dim (ReLU)\n",
    "- dropout\n",
    "- `conv2`: hidden_dim ‚Üí num_classes (logits)\n",
    "\n",
    "This model is sufficient to demonstrate message passing and achieve strong baseline performance on Cora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86042113",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1760124085135,
     "user": {
      "displayName": "Alberto Casagrande",
      "userId": "03712360769530450037"
     },
     "user_tz": -120
    },
    "id": "86042113",
    "outputId": "6e3e010c-42b4-48a1-d86a-e74a87b6b115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1433, 16)\n",
      "  (conv2): GCNConv(16, 7)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class GCN(nn.Module):\n",
    "  def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "    super().__init__()\n",
    "    self.conv1 = GCNConv(in_channels, hidden_channels) # First GCN layer: maps input features to a hidden dimension\n",
    "    self.conv2 = GCNConv(hidden_channels, out_channels) # Second GCN layer: maps hidden features to the number of output classes\n",
    "    self.dropout = dropout\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    x = self.conv1(x, edge_index) # x: node features, edge_index: graph connectivity\n",
    "    x = F.relu(x)\n",
    "    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "    x = self.conv2(x, edge_index)\n",
    "    return x\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(dataset.num_node_features, 16, dataset.num_classes, dropout=0.5).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EFyMe37qn-Y-",
   "metadata": {
    "id": "EFyMe37qn-Y-"
   },
   "source": [
    "### How `GCNConv` Uses `edge_index`\n",
    "\n",
    "The `edge_index` is crucial for the `GCNConv` layers. During the forward pass, the `GCNConv` layer performs **message passing** using `data.x` and `data.edge_index`. For each node, it:\n",
    "\n",
    "1.  **Gathers Neighbor Features:** Uses `edge_index` to identify direct neighbors and collects their features (`data.x` from the previous layer).\n",
    "2.  **Aggregates Features:** Combines the gathered neighbor features into a single vector (typically by summing or averaging, often with normalization).\n",
    "3.  **Transforms and Updates:** Combines the aggregated neighbor features with the node's own features, applies a linear transformation (learned weights), and passes the result through an activation function (like ReLU) to get the node's updated feature vector for the next layer.\n",
    "\n",
    "Essentially, `edge_index` acts as a roadmap for `GCNConv`, guiding the aggregation of information from connected nodes, allowing the network to learn representations that incorporate local graph structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76f65c",
   "metadata": {
    "id": "9d76f65c"
   },
   "source": [
    "## Training and Evaluation (full-batch)\n",
    "\n",
    "For small citation graphs like Cora, PyG uses **full-batch training**: every forward pass uses the entire graph (all nodes and edges). We compute the loss only on the nodes specified by `train_mask`.\n",
    "\n",
    "We implement `train()` and `evaluate()` helper functions. Note that during evaluation we compute accuracy on train/val/test splits using the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20fdb24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1760124264420,
     "user": {
      "displayName": "Alberto Casagrande",
      "userId": "03712360769530450037"
     },
     "user_tz": -120
    },
    "id": "e20fdb24",
    "outputId": "b893c1fc-347c-4111-f501-001f0d8ee358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training & evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "  model.train()\n",
    "  optimizer.zero_grad() # Clear old gradients\n",
    "  out = model(data.x, data.edge_index) # Perform a single forward pass\n",
    "  loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask]) # Calculate the loss only on the training nodes\n",
    "  loss.backward() # Derive gradients\n",
    "  optimizer.step() # Update parameters\n",
    "  return loss.item()\n",
    "\n",
    "def evaluate():\n",
    "  model.eval()\n",
    "  out = model(data.x, data.edge_index)\n",
    "  pred = out.argmax(dim=1) # Use the class with the highest score\n",
    "  accs = []\n",
    "\n",
    "  for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "    correct = int((pred[mask] == data.y[mask]).sum())\n",
    "    accs.append(correct / int(mask.sum()))\n",
    "  return accs\n",
    "\n",
    "print('Training & evaluation functions defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0263565",
   "metadata": {
    "id": "c0263565"
   },
   "source": [
    "### Full training loop\n",
    "\n",
    "Below is a standard training loop. We train for `num_epochs` and print metrics every few epochs. For reproducibility you may set manual seeds. For production experiments, consider using early stopping and learning rate schedules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41545a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1760124415714,
     "user": {
      "displayName": "Alberto Casagrande",
      "userId": "03712360769530450037"
     },
     "user_tz": -120
    },
    "id": "a41545a4",
    "outputId": "053bd5ef-6c80-4b1f-8b73-a22c70eae32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch: 010, Loss: 0.8534, Train Acc: 0.9571, Val Acc: 0.7280, Test: 0.7450\n",
      "Epoch: 020, Loss: 0.2933, Train Acc: 0.9857, Val Acc: 0.7720, Test: 0.7840\n",
      "Epoch: 030, Loss: 0.1297, Train Acc: 1.0000, Val Acc: 0.7680, Test: 0.7870\n",
      "Epoch: 040, Loss: 0.0547, Train Acc: 1.0000, Val Acc: 0.7660, Test: 0.7800\n",
      "Epoch: 050, Loss: 0.0643, Train Acc: 1.0000, Val Acc: 0.7700, Test: 0.7800\n",
      "Epoch: 060, Loss: 0.0600, Train Acc: 1.0000, Val Acc: 0.7760, Test: 0.7890\n",
      "Epoch: 070, Loss: 0.0609, Train Acc: 1.0000, Val Acc: 0.7820, Test: 0.7970\n",
      "Epoch: 080, Loss: 0.0418, Train Acc: 1.0000, Val Acc: 0.7800, Test: 0.7980\n",
      "Epoch: 090, Loss: 0.0458, Train Acc: 1.0000, Val Acc: 0.7840, Test: 0.7950\n",
      "Epoch: 100, Loss: 0.0385, Train Acc: 1.0000, Val Acc: 0.7820, Test: 0.8060\n",
      "Epoch: 110, Loss: 0.0422, Train Acc: 1.0000, Val Acc: 0.7800, Test: 0.8000\n",
      "Epoch: 120, Loss: 0.0379, Train Acc: 1.0000, Val Acc: 0.7720, Test: 0.7930\n",
      "Epoch: 130, Loss: 0.0346, Train Acc: 1.0000, Val Acc: 0.7680, Test: 0.7950\n",
      "Epoch: 140, Loss: 0.0327, Train Acc: 1.0000, Val Acc: 0.7700, Test: 0.7970\n",
      "Epoch: 150, Loss: 0.0460, Train Acc: 1.0000, Val Acc: 0.7620, Test: 0.7970\n",
      "Epoch: 160, Loss: 0.0265, Train Acc: 1.0000, Val Acc: 0.7660, Test: 0.8010\n",
      "Epoch: 170, Loss: 0.0289, Train Acc: 1.0000, Val Acc: 0.7740, Test: 0.8050\n",
      "Epoch: 180, Loss: 0.0203, Train Acc: 1.0000, Val Acc: 0.7780, Test: 0.8030\n",
      "Epoch: 190, Loss: 0.0179, Train Acc: 1.0000, Val Acc: 0.7640, Test: 0.7950\n",
      "Epoch: 200, Loss: 0.0425, Train Acc: 1.0000, Val Acc: 0.7540, Test: 0.7980\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "print('Starting training...')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  loss = train()\n",
    "  if epoch % 10 == 0:\n",
    "    train_acc, val_acc, test_acc = evaluate()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c8cb06",
   "metadata": {
    "id": "49c8cb06"
   },
   "source": [
    "## Inspecting predictions on specific test nodes\n",
    "\n",
    "After training, it's often useful to inspect individual predictions. We pick a few random test nodes and print their true and predicted labels. If available, we map numeric labels to class names (Cora's 7 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "658a25a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1760124815666,
     "user": {
      "displayName": "Alberto Casagrande",
      "userId": "03712360769530450037"
     },
     "user_tz": -120
    },
    "id": "658a25a5",
    "outputId": "e2e3d531-7817-45fa-ed15-2fb1081eb0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 2115 True: 3 Pred: 3\n",
      "Node 2292 True: 4 Pred: 4\n",
      "Node 1854 True: 1 Pred: 3\n",
      "Node 2151 True: 6 Pred: 6\n",
      "Node 1942 True: 3 Pred: 3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "test_nodes = torch.where(data.test_mask)[0]\n",
    "sampled = test_nodes[torch.randperm(len(test_nodes))[:5]]\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = model(data.x, data.edge_index)\n",
    "  preds = out.argmax(dim=1)\n",
    "\n",
    "  for n in sampled:\n",
    "    print('Node', int(n), 'True:', int(data.y[n]), 'Pred:', int(preds[n]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
